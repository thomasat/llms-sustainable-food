{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e7f62e-fb0d-4f59-8183-3f5e6fa12f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import math\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "import getpass\n",
    "\n",
    "from helm.common.authentication import Authentication\n",
    "from helm.common.perspective_api_request import PerspectiveAPIRequest, PerspectiveAPIRequestResult\n",
    "from helm.common.request import Request, RequestResult\n",
    "from helm.common.tokenization_request import TokenizationRequest, TokenizationRequestResult\n",
    "from helm.proxy.accounts import Account\n",
    "\n",
    "from helm.proxy.services.remote_service import RemoteService\n",
    "\n",
    "import gurobipy as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c2244-e073-4a34-8191-2198ee57bbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_llms = ['anthropic/claude-3-5-sonnet-20240620',\n",
    "              'openai/gpt-3.5-turbo-0125',\n",
    "              'openai/gpt-4o-2024-05-13',\n",
    "              'meta/llama-3.1-70b-instruct-turbo',\n",
    "             'google/gemini-1.5-pro-001',\n",
    "             'openai/o1-preview-2024-09-12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7620f245-045a-4421-9ad0-42c08a995e0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "api_key = getpass.getpass(prompt=\"Enter a valid API key: \")\n",
    "auth = Authentication(api_key='REDACTED')\n",
    "service = RemoteService(\"REDACTED\")\n",
    "\n",
    "# Access account and show my current quotas and usages\n",
    "account: Account = service.get_account(auth)\n",
    "print(account.usages.keys())\n",
    "\n",
    "for key in account.usages.keys():\n",
    "    print(key, account.usages[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683f7d20",
   "metadata": {},
   "source": [
    "# Define parameters and data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9619b5e5-9b96-458c-9ef4-986da5f1b034",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_same_ingredients = True #Use same ingredients as the original menu\n",
    "emissions_constraint = 0.25 #At most 25% of the expected emissions of a choice from the original menu\n",
    "animals_constraint = 1.0 #At most the expected animal usage of a choice from the original menu\n",
    "\n",
    "ratings = True # Whether to rate each generated recipe by expected preferences of the target population\n",
    "direct = False # No IQP; just directly generate a revised menu \n",
    "\n",
    "n_new = 36 # Number of new recipes to generate\n",
    "if not direct:\n",
    "    n_new = 20\n",
    "\n",
    "sim_lambda = 100 # Tradeoff between sum of expected satisfaction for each recipe individually and diversity of recipes\n",
    "\n",
    "max_corrections = 5 # Number of tries for self-correction\n",
    "\n",
    "menu_loc = 'original-nature-sust-menu_no_v.txt'\n",
    "\n",
    "with open(menu_loc, 'r') as file:\n",
    "    orig_menu = file.read()\n",
    "    \n",
    "llm = valid_llms[5]#'anthropic/claude-3-5-sonnet-20240620'#'gemini-1.5-pro'\n",
    "assert llm in valid_llms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427d58ee-3dfb-4a64-83de-04dbc8ce06a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poore and Nemecek. If not in P&N, then the table used in the Banerjee et al. Nature Sustainability paper (Appendix). \n",
    "# Per kilogram\n",
    "# https://faunalytics.org/animal-product-impact-scales/\n",
    "# https://ourworldindata.org/grapher/kilograms-meat-per-animal \n",
    "\n",
    "ingredient_emissions_map = pkl.load(open('ingredient_emissions_map.pkl', 'rb'))\n",
    "ingredient_animal_lives_map = pkl.load(open('ingredient_animal_lives_map.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db8e54-9b41-473a-8411-a613188abc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_ingredients_lower = pkl.load(open('orig_ingredients.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545b2a75-e19f-4dd4-9d6b-90cc14b8335a",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_recipes_main_ingredient = pkl.load(open('orig_recipes_main_ingredient.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec3c4d5-f30d-4a3d-956e-c1051cc1f4c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "direct_msg = \"You are a brilliant chef experienced at creating sustainable and delicious food. Here is a menu:\\n\" + orig_menu + \"\\\n",
    "\\n Please generate a revised menu, with the same number of recipes ({n}) and no new ingredients other than tofu, lentils, mushrooms, chickpeas, eggs, and cheese.\\n\\\n",
    " Design the menu to achieve at least a {frac}% CO2 emissions reduction in people's choices while maintaining or improving patron satisfaction\\\n",
    " with their set of choices. Patrons will be American omnivores. Emissions will be computed based on the main (first) ingredient. \\n\\\n",
    " Please output each recipe in same format as this example:\\n\\\n",
    " Tofu curry ramen\\n\\\n",
    " Fried tofu, noodles, curry broth, pak choi, pickled onions.\\n\\\n",
    " Appealing description.\\n\\\n",
    " The ingredients must be in order of usage, i.e the main ingredient must come first.\\n\\\n",
    " Very important: you must only use ingredients in the original menu or the list above. For every ingredient, there must be an exact match in the original menu or the list above.\\\n",
    " Do not worsen cost, nutrition, animal welfare (number of animals used, computed based on the first ingredient), or preparation time.\\n\\\n",
    " Do not include any stars, asterisks, hashtags, underscores. Do not number the recipes. Do not include any text other than recipe information, e.g. do not say `Here are the recipes'.\".format(n=n_new,\n",
    "                                                                                                                                                                                              frac=(1-emissions_constraint)*100)\n",
    "\n",
    "iqp_msg = \"You are a brilliant chef experienced at creating sustainable and delicious food. Here is a menu:\\n\" + orig_menu + \"\\\n",
    "\\n Please generate {n} new, delicious, and diverse vegan or vegetarian dishes from this set of ingredients. You are also allowed to use tofu, lentils, mushrooms, chickpeas, eggs, and cheese.\\\n",
    " Patrons will be American omnivores. \\\n",
    " Please output in same format as this example:\\n\\\n",
    " Tofu curry ramen\\n\\\n",
    " Fried tofu, noodles, curry broth, pak choi, pickled onions.\\n\\\n",
    " Appealing description.\\n\\\n",
    " The ingredients must be in order of usage, i.e the main ingredient must come first.\\n\\\n",
    " Very important: you must only use ingredients in the original menu or the list above. For every ingredient, there must be an exact match in the original menu or the list above.\\\n",
    " Do not worsen CO2 emissions, cost, nutrition, or preparation time. Emissions will be computed based on the main (first) ingredient. \\n\\\n",
    " Do not include any stars, asterisks, hashtags, underscores. Do not number the recipes. Do not include any text other than recipe information, e.g. do not say `Here are the recipes'.\".format(n=n_new)\n",
    "\n",
    "msg = iqp_msg\n",
    "\n",
    "if direct:\n",
    "    msg = direct_msg\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ef7c85-4d36-4961-a834-117791eca170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_emissions(main_ingredient, emissions_map):\n",
    "    for key in emissions_map:\n",
    "        for val in emissions_map[key]:\n",
    "            if val in main_ingredient:\n",
    "                return key\n",
    "\n",
    "def compute_animal_lives(main_ingredient, animal_map):\n",
    "    for key in animal_map:\n",
    "        for val in animal_map[key]:\n",
    "            if val in main_ingredient:\n",
    "                return key\n",
    "    return 0\n",
    "\n",
    "def check_ingredient(ingredient, ingredient_set):\n",
    "    processed_ingredient = process_ingredient(ingredient)\n",
    "    \n",
    "    if processed_ingredient in ingredient_set:\n",
    "        return True\n",
    "    if any(processed_ingredient in base_ingredient for base_ingredient in ingredient_set):\n",
    "        return True\n",
    "    if any(base_ingredient in processed_ingredient for base_ingredient in ingredient_set):\n",
    "        return True\n",
    "\n",
    "def process_ingredient(ingredient):\n",
    "    if ingredient[-1] == '.':\n",
    "        ingredient = ingredient[:-1]\n",
    "    return ingredient.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509cc21c-7e39-4e52-afc1-9769c4402333",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check:\n",
    "- Requested number of recipes\n",
    "- All ingredients must be mentioned in the original menu, exact match only\n",
    "\"\"\"\n",
    "def check_response(response, expected_num_recipes, check_main_ingredient_only=True):\n",
    "    recipes = response.strip().split('\\n\\n')\n",
    "\n",
    "    num_recipes = len(recipes)\n",
    "\n",
    "    invalid_ingredients = []\n",
    "    for recipe in recipes:\n",
    "        parts = recipe.split('\\n')\n",
    "        ingredients = parts[1].split(', ')\n",
    "        print('ingredients: ', ingredients)\n",
    "        if check_main_ingredient_only:\n",
    "            if not check_ingredient(ingredients[0], orig_ingredients_lower):\n",
    "                invalid_ingredients.append(ingredients[0])\n",
    "        else:\n",
    "            for ingredient in ingredients:\n",
    "                if not check_ingredient(ingredient, orig_ingredients_lower):\n",
    "                    invalid_ingredients.append(ingredient)                \n",
    "    \n",
    "    return num_recipes, invalid_ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba58b97-1176-4bf6-bec9-9676de246525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_llm(prompt, llm):\n",
    "    # Make a request\n",
    "    mx_tokens = 4096\n",
    "    if llm == 'openai/o1-preview-2024-09-12':\n",
    "        mx_tokens = 32768\n",
    "    request = Request(\n",
    "        model=llm, prompt=prompt, echo_prompt=False,\n",
    "        max_tokens=mx_tokens,\n",
    "    )\n",
    "    request_result: RequestResult = service.make_request(auth, request)\n",
    "    return request_result.completions[0].text\n",
    "\n",
    "def gen_ranking_str(all_recipes, idx_start, idx_end):\n",
    "    ranking_str = ''\n",
    "    idx = idx_start\n",
    "    while idx < idx_end and idx < len(all_recipes):\n",
    "        ranking_str += all_recipes[idx][0] + '\\n'  \n",
    "        idx+=1 \n",
    "    return ranking_str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93309285",
   "metadata": {},
   "source": [
    "# Prompt LLM; check that number of recipes is correct and that ingredients are valid. Allow for up to 5 tries for self-correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4106b0-3961-426f-81f2-eeaefe8dd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = prompt_llm(msg, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725fcfaa-fa5b-45c1-9e79-44efdcc64a8f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "response.strip().split('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31fc831-e45c-4cd1-9ea8-f39949100b46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_recipes, invalid_ingredients = check_response(response, n_new, check_main_ingredient_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23dc01d-66e6-4bbc-894c-b23148afe610",
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_ingredients, num_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165cfad-545c-4a3e-9e65-7c3d0eeba016",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_response_generated = (num_recipes >= n_new) and len(invalid_ingredients) == 0\n",
    "valid_response_generated, num_recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fa51d-42a5-45fe-b39c-edf00eec18c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iters = 0\n",
    "while not valid_response_generated and iters <= max_corrections:\n",
    "    corrective_msg = ''\n",
    "    if num_recipes != n_new:\n",
    "        corrective_msg += 'You generated an invalid number of recipes ({act} rather than {expected}), as determined by line breaks.\\\n",
    "        This may also be due to not following the formatting instructions.\\n'.format(act=num_recipes, expected=n_new)\n",
    "\n",
    "    if len(invalid_ingredients) > 0:\n",
    "        corrective_msg += 'You used invalid ingredients: {invld}. You may have been close, but recall that every ingredient must have an EXACT match in the original menu.\\n'.format(invld=invalid_ingredients)\n",
    "\n",
    "    corrective_msg += 'Now I\\'ll repeat the original prompt:\\n'\n",
    "\n",
    "    new_msg = corrective_msg + msg\n",
    "\n",
    "    print(new_msg)\n",
    "    \n",
    "    response = prompt_llm(new_msg,llm)\n",
    "    num_recipes, invalid_ingredients = check_response(response, n_new)\n",
    "    valid_response_generated = (num_recipes == n_new) and len(invalid_ingredients) == 0\n",
    "\n",
    "    iters += 1\n",
    "\n",
    "print(corrective_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6bbe6a-4e13-4c2d-a80e-c0971d3a5547",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not valid_response_generated:\n",
    "    assert 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0adf9d2e-2768-4c73-bc11-a0394a3e3b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "recipes = response.split('\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7af041",
   "metadata": {},
   "source": [
    "# Compute emissions and animal welfare properties of LLM generated recipes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad50044a-7c55-4c2e-8566-e28ad6fe0a87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_recipes = []\n",
    "\n",
    "# All_recipes tuple: name, description, emissions, animals, LLM_generated\n",
    "\n",
    "# Add LLM generated recipes\n",
    "for recipe in recipes:\n",
    "    print(recipe)\n",
    "    parts = recipe.split('\\n')\n",
    "    ingredients = parts[1].split(', ')\n",
    "    name = parts[0]\n",
    "    #print(ingredients[0])\n",
    "    description = parts[2]\n",
    "\n",
    "    emissions = compute_emissions(ingredients[0].lower(), ingredient_emissions_map)\n",
    "    animals = compute_animal_lives(ingredients[0].lower(), ingredient_animal_lives_map)\n",
    "    \n",
    "    if emissions is None:\n",
    "        print(name)\n",
    "        print(ingredients[0].lower())\n",
    "        assert 0\n",
    "    \n",
    "    all_recipes.append([name, description, emissions, animals, 1, ingredients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588af7cf-6ec3-4501-afd4-ad90acfb6a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35d16ea-28c5-40f3-8ffc-bffa5df73862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit emissions and animal constraints to expected values\n",
    "# \\sum e_i s_i <= kConstraint --> \\sum e_i r_i s_i <= Constraint (\\sum r_i s_i) where higher r_i is more liked\n",
    "# Constraint should be \\sum e_i w_i in original menu. Expected emissions in original menu. \n",
    "def solve_iqp(all_recipes, orig_subset, emissions_frac, animal_frac):\n",
    "    # Create a new model\n",
    "    m = gp.Model()\n",
    "    \n",
    "    # Create variables\n",
    "    vars = []\n",
    "    obj = 0\n",
    "    k = len(orig_subset)\n",
    "    \n",
    "    card_constraint = 0\n",
    "    emissions_constraint = 0\n",
    "    animals_constraint = 0\n",
    "    #nutr_constraint = 0\n",
    "    #cost_constraint = 0\n",
    "\n",
    "    rating_idx = 6\n",
    "    emissions_idx = 2\n",
    "    animals_idx = 3\n",
    "\n",
    "    orig_subset_preference_totals = sum(r[rating_idx] for r in orig_subset)\n",
    "    emissions_ev = sum(r[emissions_idx]*r[rating_idx] for r in orig_subset)/orig_subset_preference_totals\n",
    "    animals_ev = sum(r[animals_idx]*r[rating_idx] for r in orig_subset)/orig_subset_preference_totals\n",
    "\n",
    "    print('orig_subset_preference_totals: ', orig_subset_preference_totals)\n",
    "    print('emissions_ev: ', emissions_ev)\n",
    "    print('animals_ev: ', animals_ev)\n",
    "    \n",
    "    # Average across the original menu\n",
    "    #emissions_val = np.mean([r[2] for r in orig_subset])\n",
    "    #animals_val = np.mean([r[3] for r in orig_subset])\n",
    "    \n",
    "    for i in range(len(all_recipes)):\n",
    "        print(i)\n",
    "        this_var = m.addVar(vtype='B', name='recipe_' + str(i))\n",
    "        rating = all_recipes[i][rating_idx]\n",
    "        obj += rating*this_var\n",
    "        vars.append(this_var)\n",
    "        card_constraint += this_var\n",
    "        emissions_constraint += this_var*all_recipes[i][emissions_idx]*all_recipes[i][rating_idx]\n",
    "        animals_constraint += this_var*all_recipes[i][animals_idx]*all_recipes[i][rating_idx]\n",
    "    \n",
    "    similarity = 0\n",
    "    for i in range(len(all_recipes)):\n",
    "        for j in range(len(all_recipes)):\n",
    "            #sim_ingr = similar(all_recipes[i]['ingredients'], all_recipes[j]['ingredients'])\n",
    "            sim_name = similar(all_recipes[i][0], all_recipes[j][0])\n",
    "            similarity = sim_name*vars[i]*vars[j]\n",
    "            #similarity += (sim_ingr + sim_name)*vars[i]*vars[j]\n",
    "    \n",
    "            #print('names: ', recipe_data[i]['name'], recipe_data[j]['name'], sim_name)\n",
    "            #print('ingr: ', recipe_data[i]['ingredients'], recipe_data[j]['ingredients'], sim_ingr)\n",
    "    \n",
    "    obj -= sim_lambda*similarity\n",
    "    \n",
    "    #obj = 0\n",
    "    \n",
    "    # Set objective function\n",
    "    m.setObjective(obj, gp.GRB.MAXIMIZE)\n",
    "    \n",
    "    # Add constraints\n",
    "    m.addConstr(card_constraint == k)\n",
    "\n",
    "    sumRiSi = sum(all_recipes[i][rating_idx]*vars[i] for i in range(len(vars)))\n",
    "    m.addConstr(emissions_constraint <= emissions_frac*emissions_ev*sumRiSi)\n",
    "    m.addConstr(animals_constraint <= animal_frac*animals_ev*sumRiSi)\n",
    "    \n",
    "    # Solve it!\n",
    "    m.optimize()\n",
    "\n",
    "    if not hasattr(m, 'objVal'):\n",
    "        return None\n",
    "    \n",
    "    print(f\"Optimal objective value: {m.objVal}\")\n",
    "    selected_recipes = []\n",
    "    \n",
    "    idx = 0\n",
    "    for var in vars:\n",
    "        print(var.X)\n",
    "        if var.X == 1.0:\n",
    "            selected_recipes.append(idx)\n",
    "        idx += 1   \n",
    "\n",
    "    return selected_recipes\n",
    "\n",
    "def select_recipe_subset(all_recipes, orig_subset, emissions_frac, animal_frac):\n",
    "    # Set up IQP\n",
    "    selected_recipes = solve_iqp(all_recipes, orig_subset, emissions_frac, animal_frac)\n",
    "\n",
    "    tries = 0\n",
    "    while selected_recipes is None and tries < 5:\n",
    "        emissions_frac += 0.1\n",
    "        print('Now rerunning with emissions_frac:', emissions_frac)\n",
    "        selected_recipes = solve_iqp(all_recipes, orig_subset, emissions_frac, animal_frac)        \n",
    "        tries += 1\n",
    "    \n",
    "    return selected_recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de4bba-5c87-4119-a92d-1ba816ab9895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End now if direct\n",
    "orig_recipes = orig_menu.split('\\n\\n')\n",
    "\n",
    "orig_subset = []\n",
    "# Add original recipes to all_recipes\n",
    "for recipe in orig_recipes:\n",
    "    name = recipe.split('.')[0]\n",
    "    description = recipe.split('.')[1]\n",
    "    print(name)\n",
    "    main_ingredient = orig_recipes_main_ingredient[name]\n",
    "\n",
    "    emissions = compute_emissions(main_ingredient.lower(), ingredient_emissions_map)\n",
    "    animals = compute_animal_lives(main_ingredient.lower(), ingredient_animal_lives_map)\n",
    "    \n",
    "    orig_subset.append([name, description, emissions, animals, 0, None])\n",
    "\n",
    "len(orig_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc5e0a2",
   "metadata": {},
   "source": [
    "# Rate recipes based on estimated preferences of target population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b704aa5-856f-494b-af3e-ab85708e4144",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "if direct:\n",
    "    selected_subset = all_recipes\n",
    "else:    \n",
    "    all_recipes = all_recipes + orig_subset\n",
    "\n",
    "    print(len(all_recipes))\n",
    "    \n",
    "    if ratings: \n",
    "        rankings = []\n",
    "        start_idx = 0\n",
    "        window_size = 5\n",
    "        end_idx = window_size\n",
    "        \n",
    "        while start_idx < len(all_recipes):\n",
    "            ranking_str = gen_ranking_str(all_recipes, start_idx, end_idx)\n",
    "            ranking_msg = 'Here are {nr} recipes. Please rate them on a scale of 1-10 based on standard American omnivore taste preferences, 1 being unappealing and 10 being appealing. Output only a comma-separated list of {nr} numbers, from 1 to 10.\\n'.format(nr=len(all_recipes[start_idx:end_idx])) + ranking_str\n",
    "            print(ranking_msg)\n",
    "            response_ranking = prompt_llm(ranking_msg, llm)\n",
    "            print(response_ranking)\n",
    "            this_rankings = [int(r) for r in response_ranking.split(',')]\n",
    "\n",
    "            rankings += this_rankings\n",
    "            start_idx += window_size\n",
    "            end_idx += window_size\n",
    "    \n",
    "        if len(rankings) != len(all_recipes):\n",
    "            print(len(rankings))\n",
    "            assert 0\n",
    "    else:\n",
    "        rankings = [10]*len(all_recipes)\n",
    "    \n",
    "    for r in range(len(all_recipes)):\n",
    "        all_recipes[r].append(rankings[r])\n",
    "\n",
    "    orig_subset = all_recipes[-len(orig_recipes):]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e73aa0",
   "metadata": {},
   "source": [
    "# Select recipe subset using IQP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94794d42-ecc9-4749-a520-6e89dbf978fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not direct:\n",
    "    selected_recipes = select_recipe_subset(all_recipes, orig_subset, emissions_constraint, animals_constraint)\n",
    "\n",
    "    metrics_selected = {'Animals': 0, 'Emissions': 0}\n",
    "    total_emissions = 0\n",
    "    total_animals = 0\n",
    "    for idx in selected_recipes:\n",
    "        print(all_recipes[idx][0])\n",
    "    \n",
    "        total_emissions += all_recipes[idx][2]\n",
    "        total_animals += all_recipes[idx][3]\n",
    "    \n",
    "    emissions_val = np.mean([r[2] for r in orig_subset])\n",
    "    animals_val = np.mean([r[3] for r in orig_subset])\n",
    "    avg_emissions = total_emissions / len(selected_recipes)\n",
    "    avg_animals = total_animals / len(selected_recipes)\n",
    "    \n",
    "    print('Orig avg emissions :', emissions_val)\n",
    "    print('Orig avg animals :', animals_val)\n",
    "    print('Avg emissions in selected subset: ', avg_emissions)\n",
    "    print('Avg animals in selected subset: ', avg_animals)\n",
    "\n",
    "    selected_subset = [all_recipes[s] for s in selected_recipes]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941ba269",
   "metadata": {},
   "source": [
    "# Store solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449c1974-2849-4b55-ab64-48dbdc9ee105",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = pd.DataFrame(orig_subset)#pd.DataFrame(all_recipes[19:])\n",
    "if direct:\n",
    "    col_map = {0:'Name', 1:'Description', 2:'Emissions', 3:'Animal Lives', 4: 'LLM Generated', 5: 'Ingredients'}\n",
    "else:\n",
    "    col_map = {0:'Name', 1:'Description', 2:'Emissions', 3:'Animal Lives', 4: 'LLM Generated', 5: 'Ingredients', 6: 'Predicted Rating'}\n",
    "orig_df = orig_df.rename(columns=col_map)\n",
    "orig_df.to_csv('orig-menu-df.csv',index=False)\n",
    "\n",
    "selected_df = pd.DataFrame(selected_subset)\n",
    "selected_df = selected_df.rename(columns=col_map)\n",
    "#selected_df = selected_df.sort_values(['LLM Generated', 'Predicted Rating'], ascending=[False, True]) #'Emissions', \n",
    "if not direct:\n",
    "    selected_df = selected_df.sort_values(['LLM Generated', 'Predicted Rating'], ascending=[False, False]) #'Emissions', \n",
    "    #selected_df = selected_df.sort_values(['Predicted Rating', 'Emissions'], ascending=[True, True]) #'Emissions', \n",
    "if direct:\n",
    "    selected_df.to_csv('direct-' + llm.split('/')[1] + '-generated-menu.csv',index=False)\n",
    "else:\n",
    "    selected_df.to_csv('iqp-' + llm.split('/')[1] + '-generated-menu.csv',index=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27725906-6c44-4cc3-a243-73317691beac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text for original menu\n",
    "orig_text = ''\n",
    "for idx in range(orig_df.shape[0]):\n",
    "    output = orig_df.iloc[idx, 0] + '. ' + orig_df.iloc[idx, 1]\n",
    "    if output[-1] != '.':\n",
    "        output += '.'\n",
    "    orig_text += str(idx + 1) + '. ' + output + '\\n'\n",
    "print(orig_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7273dbcb-9d1b-46f9-8dd5-925dd02bc281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Text for LLM generated menu\n",
    "llm_text = ''\n",
    "for idx in range(selected_df.shape[0]):\n",
    "    output = selected_df.iloc[idx, 0] + '. ' + selected_df.iloc[idx, 1]\n",
    "    if output[-1] != '.':\n",
    "        output += '.'\n",
    "    llm_text += str(idx + 1) + '. ' + output + '\\n'\n",
    "print(llm_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6afc758-6dc3-4f0b-9996-32995d56dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_menu_loc = 'orig-menu.txt'\n",
    "with open(orig_menu_loc, 'w') as f:\n",
    "    f.write(orig_text)\n",
    "\n",
    "llm_menu_loc = 'iqp-' + llm.split('/')[1] + '-generated-menu.txt'\n",
    "if direct:\n",
    "    llm_menu_loc = 'direct-' + llm.split('/')[1] + '-generated-menu.txt'\n",
    "\n",
    "with open(llm_menu_loc, 'w') as f:\n",
    "    f.write(llm_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
