{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb88f8b0-e735-4678-aaa2-ad0d28d6ae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b58ef2fd-6777-441a-b6b6-16ffc875e760",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('recent_recipes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d537be4-178a-447c-b298-9057f93c2da1",
   "metadata": {},
   "source": [
    "### 1. Setup comparison pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201cbbac-9d9d-413b-832d-242b6be0b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all possible pairs of rows\n",
    "pairs = list(combinations(df.index, 2))\n",
    "\n",
    "# Display the results\n",
    "pairs_df = pd.DataFrame(pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a28e7e0-0f3f-4f1a-911a-50c191f073be",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pairs = []\n",
    "for _,row in pairs_df.iterrows():\n",
    "    \n",
    "    #print(row['Pair'][0], row['Pair'][1])\n",
    "    item1 = df.loc[row[0]]\n",
    "    item2 = df.loc[row[1]]\n",
    "    \n",
    "    if item1['Rating']!=item2['Rating']:\n",
    "        pair = {}\n",
    "\n",
    "        pair['id_1'] = row[0]\n",
    "        pair['id_2'] = row[1]\n",
    "\n",
    "        pair['text_1'] = item1['Recipe']\n",
    "        pair['text_2'] = item2['Recipe']\n",
    "\n",
    "        pair['actual_score_1'] = item1['Rating']\n",
    "        pair['actual_score_2'] = item2['Rating']\n",
    "\n",
    "        list_pairs.append(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4803835-a369-428f-aa2d-36d9e42c1a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = pd.DataFrame(list_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96b9dfd5-018d-4445-9243-3eb8ed707fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs['delta'] = (df_pairs['actual_score_1'] - df_pairs['actual_score_2']).abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "285e8af3-8419-4d00-8fb9-7684387befbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs = df_pairs.loc[df_pairs['delta']>0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "232ea77e-ddba-4d6f-942f-1523b74ba09b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pairs.reset_index().to_csv('recipe_pairs_recent.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c8bf0-1ad4-4f6b-bbd7-14907c962df4",
   "metadata": {},
   "source": [
    "### 2. Collect predctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6e1ea3f-4843-44bf-bbee-5629f2d3d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('recipe_pairs_recent.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f2ab83f-4f93-4060-a35a-34365c27ad65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import helm\n",
    "\n",
    "from helm.common.authentication import Authentication\n",
    "from helm.common.perspective_api_request import PerspectiveAPIRequest, PerspectiveAPIRequestResult\n",
    "from helm.common.request import Request, RequestResult\n",
    "from helm.common.tokenization_request import TokenizationRequest, TokenizationRequestResult\n",
    "from helm.proxy.accounts import Account\n",
    "\n",
    "#google, gpt3, gpt4, anthropic and together\n",
    "from helm.proxy.services.remote_service import RemoteService\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a5b38ca0-0c36-4fc7-a942-6fcbc4d8bbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a valid API key:  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['gpt3', 'gpt4', 'codex', 'jurassic', 'gooseai', 'cohere', 'dall_e', 'together_vision', 'simple', 'together', 'anthropic', 'google', 'o1'])\n",
      "gpt3 {'daily': Usage(period='2024-12-22', used=301, quota=None), 'monthly': Usage(period='2024-12', used=301, quota=None), 'total': Usage(period='all', used=1325509, quota=10000000)}\n",
      "gpt4 {'daily': Usage(period='2024-12-22', used=290, quota=None), 'monthly': Usage(period='2024-12', used=290, quota=None), 'total': Usage(period='all', used=1443087, quota=10000000)}\n",
      "codex {'daily': Usage(period=None, used=0, quota=10000)}\n",
      "jurassic {'daily': Usage(period=None, used=0, quota=10000)}\n",
      "gooseai {'daily': Usage(period=None, used=0, quota=10000)}\n",
      "cohere {'daily': Usage(period=None, used=0, quota=10000)}\n",
      "dall_e {'daily': Usage(period=None, used=0, quota=5)}\n",
      "together_vision {'daily': Usage(period=None, used=0, quota=30)}\n",
      "simple {'daily': Usage(period=None, used=0, quota=10000)}\n",
      "together {'daily': Usage(period='2024-12-22', used=300, quota=None), 'monthly': Usage(period='2024-12', used=300, quota=None), 'total': Usage(period='all', used=1328826, quota=10000000)}\n",
      "anthropic {'daily': Usage(period='2024-11-20', used=64248, quota=None), 'monthly': Usage(period='2024-11', used=120944, quota=None), 'total': Usage(period='all', used=1475398, quota=10000000)}\n",
      "google {'daily': Usage(period='2024-12-22', used=9944, quota=None), 'monthly': Usage(period='2024-12', used=9944, quota=None), 'total': Usage(period='all', used=2341722, quota=10000000)}\n",
      "o1 {'daily': Usage(period='2024-12-23', used=2047, quota=None), 'monthly': Usage(period='2024-12', used=1359333, quota=None), 'total': Usage(period='all', used=1800764, quota=6000000)}\n"
     ]
    }
   ],
   "source": [
    "api_key = getpass.getpass(prompt=\"Enter a valid API key: \")\n",
    "\n",
    "#add key here\n",
    "key = \"\"\n",
    "\n",
    "auth = Authentication(api_key=key)\n",
    "service = RemoteService(\"https://crfm-models.stanford.edu\")\n",
    "\n",
    "# Access account and show my current quotas and usages\n",
    "account: Account = service.get_account(auth)\n",
    "print(account.usages.keys())\n",
    "\n",
    "for key in account.usages.keys():\n",
    "    print(key, account.usages[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d74a77e-6f0b-42d2-8b72-8c167bb7a35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_llms = ['openai/o1-preview-2024-09-12','anthropic/claude-3-5-sonnet-20240620',\n",
    "              'openai/gpt-3.5-turbo-0125',\n",
    "              'openai/gpt-4o-2024-05-13',\n",
    "              'meta/llama-3.1-70b-instruct-turbo',\n",
    "             'google/gemini-1.5-pro-001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "689d50e2-f0cb-46ce-ab15-1d061cfa75f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"prompt.txt\", \"r\", encoding=\"utf-8\") as file:\n",
    "    prompt = file.read()\n",
    "\n",
    "def prompt_llm(prompt, llm):\n",
    "    if llm == 'openai/o1-preview-2024-09-12':\n",
    "        mx_tokens = 32768\n",
    "        request = Request(\n",
    "            model=llm, prompt=prompt, echo_prompt=False,\n",
    "            max_tokens=mx_tokens,\n",
    "        )\n",
    "    else:\n",
    "        request = Request(\n",
    "            model=llm, prompt=prompt, echo_prompt=False\n",
    "        )\n",
    "    request_result: RequestResult = service.make_request(auth, request)\n",
    "    return request_result.completions[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58e5f130-17da-4335-abeb-ee9e9783ca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "58it [09:36,  9.93s/it]\n"
     ]
    }
   ],
   "source": [
    "list_outputs = []\n",
    "for _,row in tqdm(df.iterrows()):\n",
    "\n",
    "    entry = {}\n",
    "    for llm in valid_llms:\n",
    "        \n",
    "        input_text = prompt + \"Recipe 1:\\n\"+row['text_1'] + \"\\n\\nRecipe 2:\\n\"+row['text_2']+ \"\\n\\nAnswer:\"\n",
    "        \n",
    "        try:\n",
    "            entry[llm] = prompt_llm(input_text, llm)\n",
    "            time.sleep(0.5)\n",
    "        except:\n",
    "            entry[llm] = np.nan\n",
    "    list_outputs.append(entry)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ab0b7ba7-a6e7-4b37-b18a-9f72a414c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list_outputs).to_csv('outputs_recent_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01b89843-22e1-48b4-bfa6-b5134bc7127f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b400269c-f0aa-42fa-b336-bfdc1925aedb",
   "metadata": {},
   "source": [
    "### 3. Analyze performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f197878-8f2e-4fcc-8cb0-2a9b69f55477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_responses_gpt_3(text):\n",
    "    if type(text)==float:\n",
    "        return text\n",
    "    if text=='Recipe 2':\n",
    "        return 2\n",
    "    elif text=='Recipe 1':\n",
    "        return 1\n",
    "    elif ('Recipe 1' in text) and ~('Recipe 2' in text):\n",
    "        return 1\n",
    "    elif ('Recipe 2' in text) and ~('Recipe 1' in text):\n",
    "        return 2\n",
    "    else:\n",
    "        return int(text)\n",
    "\n",
    "def process_responses_gemini(text):\n",
    "    if type(text)==float:\n",
    "        return text\n",
    "    if text[0]=='1' or text[0]=='2':\n",
    "        return text[0]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3d1fe296-75f7-44d8-b9d5-c929d55fee61",
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = ['openai/o1-preview-2024-09-12','anthropic/claude-3-5-sonnet-20240620',\n",
    "              'openai/gpt-3.5-turbo-0125',\n",
    "              'openai/gpt-4o-2024-05-13',\n",
    "              'meta/llama-3.1-70b-instruct-turbo',\n",
    "             'google/gemini-1.5-pro-001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dc96d4a1-cd74-49ee-a367-b5fb2de08c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[llms[2]] = df[llms[2]].apply(lambda x: process_responses_gpt_3(x))\n",
    "df[llms[5]] = df[llms[5]].apply(lambda x: process_responses_gemini(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1b293514-6c1d-483d-b8fe-69c527a95c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[llms[0]] = df[llms[0]].astype(float).astype(str)\n",
    "df[llms[1]] = df[llms[1]].astype(float).astype(str)\n",
    "df[llms[2]] = df[llms[2]].astype(float).astype(str)\n",
    "df[llms[3]] = df[llms[3]].astype(float).astype(str)\n",
    "df[llms[4]] = df[llms[4]].astype(float).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a56727c8-a996-4cd5-a43e-c8483663c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[llms[5]] = df[llms[5]].astype(float).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d494e724-91fb-4cc5-b265-d79015cff2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ground_truth'] = pd.read_csv('recipe_pairs_recent.csv').apply(lambda x: 1 if (x['actual_score_1']>x['actual_score_2']) else 2, axis = 1)\n",
    "df['ground_truth'] = df['ground_truth'].astype(float).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "323c75aa-0bc2-4a48-b4e6-94bd80141994",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['actual_score_1'] = pd.read_csv('recipe_pairs_recent.csv')['actual_score_1'].values\n",
    "df['actual_score_2'] = pd.read_csv('recipe_pairs_recent.csv')['actual_score_2'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c3706c99-02c9-49a6-8eb9-4b480fdcfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diff'] = np.abs((df['actual_score_2'] - df['actual_score_1']))\n",
    "df['bin'], bins  = pd.cut(df['diff'], bins=4, labels=False, retbins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0941e53f-15b9-432e-b827-f1f8d8c29b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fb31258-43b0-43e0-8120-e6386256f1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_e = []\n",
    "for llm in llms:\n",
    "    lowers = []\n",
    "    uppers = []\n",
    "    means = []\n",
    "\n",
    "    entry = {}\n",
    "    entry['llm'] = llm\n",
    "    entry['bin'] = 'overall'\n",
    "\n",
    "\n",
    "    entry['mean'] = sum(df['ground_truth']==df[llm])/len(df.dropna(subset=[llm]))*100\n",
    "    observed = np.array([[sum(df['ground_truth']==df[llm]), sum(df['ground_truth']!=df[llm])],\n",
    "                         [len(df[llm])/2, len(df[llm])/2]])\n",
    "    \n",
    "    chi2_stat, p_value, dof, expected = chi2_contingency(observed)\n",
    "\n",
    "    entry['p'] = p_value\n",
    "    \n",
    "    l_e.append(entry)\n",
    "    \n",
    "    for name, gr in df.dropna(subset = [llm]).groupby('bin'):\n",
    "        entry = {}\n",
    "        entry['llm'] = llm\n",
    "        entry['bin'] = name\n",
    "\n",
    "        entry['mean'] = 100*sum(gr[llm]==gr['ground_truth'])/len(gr)\n",
    "        observed = np.array([[sum(gr['ground_truth']==gr[llm]), sum(gr['ground_truth']!=gr[llm])],\n",
    "                         [len(gr[llm])/2, len(gr[llm])/2]])\n",
    "    \n",
    "        chi2_stat, p_value, dof, expected = chi2_contingency(observed)\n",
    "    \n",
    "        entry['p'] = p_value\n",
    "        \n",
    "        l_e.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cb111c1-d5eb-4e2a-b8a2-5c614953da16",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(l_e)\n",
    "table = table.pivot(index='llm', columns='bin', values='mean')\n",
    "significance = pd.DataFrame(l_e).pivot(index='llm', columns='bin', values='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1fef712-f708-48ee-a1cd-080f9a493fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting = ['openai/o1-preview-2024-09-12','openai/gpt-4o-2024-05-13',\n",
    "           'anthropic/claude-3-5-sonnet-20240620',\n",
    "           'openai/gpt-3.5-turbo-0125',\n",
    "           'meta/llama-3.1-70b-instruct-turbo',\n",
    "           'google/gemini-1.5-pro-001']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5449d78d-e951-4bc4-abd1-11eb06d1cd95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>bin</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>openai/o1-preview-2024-09-12</th>\n",
       "      <td>62.5\\%</td>\n",
       "      <td>73.08\\%</td>\n",
       "      <td>57.14\\%</td>\n",
       "      <td>77.78\\%</td>\n",
       "      <td>68.97\\%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/gpt-4o-2024-05-13</th>\n",
       "      <td>68.75\\%</td>\n",
       "      <td>42.31\\%</td>\n",
       "      <td>71.43\\%</td>\n",
       "      <td>55.56\\%</td>\n",
       "      <td>55.17\\%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anthropic/claude-3-5-sonnet-20240620</th>\n",
       "      <td>56.25\\%</td>\n",
       "      <td>50.0\\%</td>\n",
       "      <td>85.71\\%</td>\n",
       "      <td>55.56\\%</td>\n",
       "      <td>56.9\\%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>openai/gpt-3.5-turbo-0125</th>\n",
       "      <td>62.5\\%</td>\n",
       "      <td>38.46\\%</td>\n",
       "      <td>100.0\\%</td>\n",
       "      <td>55.56\\%</td>\n",
       "      <td>55.17\\%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta/llama-3.1-70b-instruct-turbo</th>\n",
       "      <td>62.5\\%</td>\n",
       "      <td>73.08\\%</td>\n",
       "      <td>100.0\\%</td>\n",
       "      <td>77.78\\%</td>\n",
       "      <td>74.14\\%*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemini-1.5-pro-001</th>\n",
       "      <td>31.25\\%</td>\n",
       "      <td>46.15\\%</td>\n",
       "      <td>42.86\\%</td>\n",
       "      <td>44.44\\%</td>\n",
       "      <td>41.38\\%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "bin                                         0        1        2        3  \\\n",
       "llm                                                                        \n",
       "openai/o1-preview-2024-09-12           62.5\\%  73.08\\%  57.14\\%  77.78\\%   \n",
       "openai/gpt-4o-2024-05-13              68.75\\%  42.31\\%  71.43\\%  55.56\\%   \n",
       "anthropic/claude-3-5-sonnet-20240620  56.25\\%   50.0\\%  85.71\\%  55.56\\%   \n",
       "openai/gpt-3.5-turbo-0125              62.5\\%  38.46\\%  100.0\\%  55.56\\%   \n",
       "meta/llama-3.1-70b-instruct-turbo      62.5\\%  73.08\\%  100.0\\%  77.78\\%   \n",
       "google/gemini-1.5-pro-001             31.25\\%  46.15\\%  42.86\\%  44.44\\%   \n",
       "\n",
       "bin                                    overall  \n",
       "llm                                             \n",
       "openai/o1-preview-2024-09-12           68.97\\%  \n",
       "openai/gpt-4o-2024-05-13               55.17\\%  \n",
       "anthropic/claude-3-5-sonnet-20240620    56.9\\%  \n",
       "openai/gpt-3.5-turbo-0125              55.17\\%  \n",
       "meta/llama-3.1-70b-instruct-turbo     74.14\\%*  \n",
       "google/gemini-1.5-pro-001              41.38\\%  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(table.round(2).astype(str) + \\\n",
    " significance.applymap(lambda x: ('\\%*') if x<0.05 else '\\%')).loc[sorting]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
